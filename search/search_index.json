{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Home","text":""},{"location":"#welcome-to-the-hexamind-library-documentation","title":"Welcome to the Hexamind library documentation","text":"<p>This documentation is the official document for the Hexamind library. </p> <p>This library is aiming to provide a simple and easy way to use and create RAG applications. </p>"},{"location":"#library-overview","title":"Library Overview","text":"<p>The library can be used in many ways. Not only for deploying RAG but it offers some useful tools to parse documents, create embeddings or use LLm models. </p>"},{"location":"ApiReference/Database/chroma_db_adapter/","title":"ChromaDbAdapter","text":""},{"location":"ApiReference/Database/chroma_db_adapter/#overview","title":"Overview","text":"<p>The <code>ChromaDbAdapter</code> class is used to interface with the chroma database. This class implements every CRUd methid inherited from the <code>IDbClient</code> class.</p>"},{"location":"ApiReference/Database/chroma_db_adapter/#chromadbadapter_1","title":"ChromaDbAdapter","text":"<p>Attributes:</p> <ul> <li><code>client</code> (ChromaClient): The chroma client used to interface with the database.</li> <li><code>collection_name</code> (str): The name of the collection in the database.</li> </ul>"},{"location":"ApiReference/Database/chroma_db_adapter/#methods","title":"Methods","text":""},{"location":"ApiReference/Database/chroma_db_adapter/#add_document","title":"add_document","text":"<p>Add a document to the chroma database.</p> <p>Parameters:</p> <ul> <li><code>document</code> (dict): The chunk to store.</li> <li><code>embedding</code>(List[float]): The embeddings related to the chunk.</li> <li><code>ids</code> (int): The ids of the chunk.</li> <li><code>metadata</code> (dict): The metadatas of the chunk.</li> </ul>"},{"location":"ApiReference/Database/chroma_db_adapter/#usage-example","title":"Usage Example","text":""},{"location":"ApiReference/Database/chroma_db_adapter/#code","title":"Code","text":"<pre><code>db_client = ChromaDbAdapter(database_path='path/to/chroma.db')\n\nfor doc, embedding, id, metadata in zip(container.chunks, container.embeddings, container.chunk_ids, container.metadatas):\n    db_client.add_document(\n        document=doc,\n        embedding=embedding,\n        ids=id,\n        metadatas=metadata\n        )\n</code></pre>"},{"location":"ApiReference/Database/chroma_db_adapter/#get_document","title":"get_document","text":"<p>Parameters:</p> <ul> <li><code>id</code> (int): The id of the document to retrieve.</li> </ul> <p>Returns:</p> <ul> <li><code>document</code> (dict): The document retrieved from the database.</li> </ul>"},{"location":"ApiReference/Database/chroma_db_adapter/#usage-example_1","title":"Usage Example","text":""},{"location":"ApiReference/Database/chroma_db_adapter/#code_1","title":"Code","text":"<pre><code>db_client = ChromaDbAdapter(database_path='path/to/chroma.db')\n\ndoc = db_client.get_document(id=1)\n</code></pre>"},{"location":"ApiReference/Database/chroma_db_adapter/#delete_document","title":"delete_document","text":"<p>Parameters:</p> <ul> <li><code>id</code> (int): The id of the document to delete.</li> </ul>"},{"location":"ApiReference/Database/chroma_db_adapter/#usage-example_2","title":"Usage Example","text":""},{"location":"ApiReference/Database/chroma_db_adapter/#code_2","title":"Code","text":"<pre><code>db_client = ChromaDbAdapter(database_path='path/to/chroma.db')\n\ndb_client.delete_document(id=1)\n</code></pre>"},{"location":"ApiReference/Database/chroma_db_adapter/#update_document","title":"update_document","text":"<p>Documentation coming soon.</p>"},{"location":"ApiReference/Database/chroma_db_adapter/#search","title":"search","text":"<p>Parameters:</p> <ul> <li><code>query</code> (str): The query to search for.</li> <li><code>num_results</code> (int): The number of results to return.</li> </ul> <p>Returns:</p> <ul> <li><code>results</code> (List[dict]): The results of the search.</li> </ul>"},{"location":"ApiReference/Database/chroma_db_adapter/#usage-example_3","title":"Usage Example","text":""},{"location":"ApiReference/Database/chroma_db_adapter/#code_3","title":"Code","text":"<pre><code>db_client = ChromaDbAdapter(database_path='path/to/chroma.db')\nquery_embedding = np.random.rand(1, 768)\nresults = db_client.search(query=query_embedding, num_results=10)\n</code></pre>"},{"location":"ApiReference/Database/chroma_db_adapter/#get","title":"get","text":"<p>This method is exclusive to the <code>ChromaDbAdapter</code> class. It is used to get all the documents in the database.</p> <p>Returns:</p> <ul> <li><code>documents</code> (List[dict]): The documents in the database.</li> </ul>"},{"location":"ApiReference/Database/chroma_db_adapter/#usage-example_4","title":"Usage Example","text":""},{"location":"ApiReference/Database/chroma_db_adapter/#code_4","title":"Code","text":"<pre><code>db_client = ChromaDbAdapter(database_path='path/to/chroma.db')\ndocuments = db_client.get()\n</code></pre>"},{"location":"ApiReference/Database/db_adapters/","title":"Database Adpaters Factory","text":""},{"location":"ApiReference/Database/db_adapters/#overview","title":"Overview","text":"<p>The database adapters are responsible for interfacing with vector databases. </p> <p>Currently, hexamind supports only two databases which are chromadb and Elasticsearch. Please note that the Elasticsearch database is still under development.</p> <p>A factory class is  available to create the database adapter based on the database type.</p>"},{"location":"ApiReference/Database/db_adapters/#dbadapterfactory","title":"DbAdapterFactory","text":"<p>The <code>DbAdapterFactory</code> class is used tp instanciate the proper database adapter based on the database type.</p>"},{"location":"ApiReference/Database/db_adapters/#create_adapter","title":"create_adapter","text":"<p>Create a database adapter based on the database type.</p> <p>Parameters:</p> <ul> <li><code>db_name</code> (str): The name of the database. ('chroma' or 'elasticsearch')</li> <li><code>collection_name</code> (str): The name of the collection in the database. Default is None.</li> <li><code>kwargs</code> (dict): The keyword arguments to pass to the database adapter.<ul> <li>ChromaDbAdapter:<ul> <li><code>database_path</code> (str): The path to the chroma file.</li> </ul> </li> </ul> </li> </ul> <p>Returns:</p> <ul> <li>Database Adapter (<code>IDbClient</code>): Returns on instance of the database adpater. This type will always be an <code>IDbClient</code>.  <ul> <li><code>ChromaDbAdapter</code>: If the db_name is 'chroma'.</li> <li><code>ElasticSearchAdapter</code>: If the db_name is 'elasticsearch'.</li> </ul> </li> </ul>"},{"location":"ApiReference/Database/db_adapters/#usage-example","title":"Usage Example","text":""},{"location":"ApiReference/Database/db_adapters/#code","title":"Code","text":"<pre><code>db_adapter = DbAdapterFactory.create_adapter(db_name='chroma', collection_name='chunks', database_path='path/to/chroma.db')\n\nprint(type(db_adapter))\n</code></pre>"},{"location":"ApiReference/Database/db_adapters/#output","title":"Output","text":"<pre><code>&lt;class 'hxm_rag.database.adapters.ChromaDbAdapter.ChromaDbAdapter'&gt;\n</code></pre>"},{"location":"ApiReference/Database/db_adapters/#idbclient","title":"IDbClient","text":"<p>Each of the adapters implement these methods from the <code>IDbClient</code> class. Basically all of the CRUD operations.</p> <ul> <li><code>add_document</code>: Add a document to the database.</li> <li><code>get_document</code>: Get a document from the database.</li> <li><code>delete_document</code>: Delete a document from the database.</li> <li><code>update_document</code>: Update a document in the database.</li> <li><code>search</code>: Search for documents in the database.</li> </ul>"},{"location":"ApiReference/Database/elastic_db_adapter/","title":"ElasticSearchAdapter","text":"<p>Documentation coming soon.</p>"},{"location":"ApiReference/Database/ingestion/","title":"Ingestor","text":""},{"location":"ApiReference/Database/ingestion/#overview","title":"Overview","text":"<p>The ingestor is the component responsible for ingesting the data into the vector databases. The ingestor creates the embeddings, populate content and metadata, and store the data in the database. </p>"},{"location":"ApiReference/Database/ingestion/#ingestor_1","title":"Ingestor","text":"<p>Parameters:</p> <ul> <li><code>db_client</code> (AbstractDb) : The database client to use.</li> <li><code>llm_agent</code> (LlmAgent): The LLM agent to use.</li> </ul>"},{"location":"ApiReference/Database/ingestion/#methods","title":"Methods","text":""},{"location":"ApiReference/Database/ingestion/#store_container","title":"store_container","text":"<p>Store a container in the database. </p> <p>The method will ingest recursively all the container from the input container. When we talk about ingesting container that means ingesting the content of the container. Each content as associated metadata,  embeddings and ids.</p> <p>To get more information about the container, check the Container documentation.</p> <p>Parameters:</p> <ul> <li><code>container</code> (Container): The container to store.</li> </ul>"},{"location":"ApiReference/Database/ingestion/#usage-example","title":"Usage Example","text":""},{"location":"ApiReference/Database/ingestion/#code","title":"Code","text":"<pre><code>ingestor = Ingestor(db_client=ChromaDbAdapter(database_path='path/to/chroma.db'), llm_agent=llm_agent)\n\ndict_structure = WordReader(\"path/to/word_file\").get_document_structure()\ndocument = Document(dict_structure)\ndoc.root_container.get_embeddings(llm_agent=llm_agent)\ningestor.store_container(container=document.root_container)\n</code></pre>"},{"location":"ApiReference/Database/ingestion/#store_container_summaries","title":"store_container_summaries","text":"<p>Store the summaries of a container in the database.</p> <p>This method will ingest recursively all the summary associated to a container. </p> <p>To get more information about the container, check the Container documentation.</p> <p>Parameters:</p> <ul> <li><code>container</code> (Container): The container to store.</li> </ul>"},{"location":"ApiReference/Database/ingestion/#usage-example_1","title":"Usage Example","text":""},{"location":"ApiReference/Database/ingestion/#code_1","title":"Code","text":"<pre><code>ingestor = Ingestor(db_client=ChromaDbAdapter(database_path='path/to/chroma.db'), llm_agent=llm_agent)\n\ndict_structure = WordReader(\"path/to/word_file\").get_document_structure()\ndocument = Document(dict_structure)\ndoc.root_container.get_summaries(llm_agent=llm_agent)\ningestor.store_container(container=document.root_container)\n</code></pre>"},{"location":"ApiReference/Database/ingestion/#ingest_content","title":"ingest_content","text":"<p>Ingest the content of a document. This method streamlines the whole process of ingesting a document. From creating the embeddings to storing the data in the database. So it will use the <code>store_container</code> method. </p> <p>Parameters:</p> <ul> <li><code>document</code> (Document): The document to ingest.</li> </ul>"},{"location":"ApiReference/Database/ingestion/#usage-example_2","title":"Usage Example","text":""},{"location":"ApiReference/Database/ingestion/#code_2","title":"Code","text":"<pre><code>ingestor = Ingestor(db_client=ChromaDbAdapter(database_path='path/to/chroma.db'), llm_agent=llm_agent)\n\ndict_structure = WordReader(\"path/to/word_file\").get_document_structure()\n\ndocument = Document(dict_structure)\n\ningestor.ingest_content(document=document)\n</code></pre>"},{"location":"ApiReference/Database/ingestion/#ingest_summaries","title":"ingest_summaries","text":"<p>Ingest the summaries of a document. This method streamlines the whole process of ingesting a document summaries. From creating the embeddings to storing the data in the database. So it will use the <code>store_container_summaries</code> method.</p> <p>Parameters:</p> <ul> <li><code>document</code> (Document): The document to ingest.</li> </ul>"},{"location":"ApiReference/Database/ingestion/#usage-example_3","title":"Usage Example","text":""},{"location":"ApiReference/Database/ingestion/#code_3","title":"Code","text":"<pre><code>ingestor = Ingestor(db_client=ChromaDbAdapter(database_path='path/to/chroma.db'), llm_agent=llm_agent)\n\ndict_structure = WordReader(\"path/to/word_file\").get_document_structure()\n\ndocument = Document(dict_structure)\n\ningestor.ingest_summaries(document=document)\n</code></pre>"},{"location":"ApiReference/Initializer/initializer/","title":"Initializer","text":""},{"location":"ApiReference/Initializer/initializer/#overview","title":"Overview","text":"<p>The purpose of this classs is to provide a simple and fast way to initialize your database and your Llm agent.  This initializer will use the two factories :</p> <ul> <li><code>DbAdapterFactory</code> to create the database</li> <li><code>LlmAdapterFactory</code> to create the llm client</li> </ul> <p>Attributes:</p> <ul> <li><code>db_name</code> (str): The name of the database.</li> <li><code>database_path</code> (str): The path to the database.</li> <li><code>collection_name</code> (str): The name of the collection in the database.</li> <li><code>llm_name</code> (str): The name of the llm model you want to use</li> <li><code>llm_api_key</code> (str): The api key of the llm model you want to use</li> <li><code>model</code> (str): The model to use for the llm agent.</li> <li><code>embed_model</code> (str): The model to use for the embeddings.</li> </ul>"},{"location":"ApiReference/Initializer/initializer/#usage-example","title":"Usage Example","text":""},{"location":"ApiReference/Initializer/initializer/#code","title":"Code","text":"<pre><code>initializer = Initializer(\n    db_name='chroma',\n    database_path='path/to/chroma.db',\n    collection_name='chunks',\n    llm_name='mistral',\n    llm_api_key='api_key',\n    model='mistral-large',\n    embed_model='mistral-embed')\n</code></pre>"},{"location":"ApiReference/Initializer/initializer/#output","title":"output","text":"<pre><code>&lt;class 'hxm_rag.initializer.initializer.Initializer'&gt;\n</code></pre>"},{"location":"ApiReference/Initializer/initializer/#methods","title":"Methods","text":""},{"location":"ApiReference/Initializer/initializer/#initialize_database","title":"initialize_database","text":"<p>This method instanciate the database client based on the configuration provided in the initializer.</p> <p>Returns:</p> <ul> <li><code>IDbClient</code>: The database client.</li> </ul>"},{"location":"ApiReference/Initializer/initializer/#usage-example_1","title":"Usage Example","text":""},{"location":"ApiReference/Initializer/initializer/#code_1","title":"Code","text":"<pre><code>db_adapter = initializer.initialize_database()\n\nprint(type(db_adapter))\n</code></pre>"},{"location":"ApiReference/Initializer/initializer/#output_1","title":"output","text":"<pre><code>&lt;class 'hxm_rag.database.adapters.ChromaDbAdapter.ChromaDbAdapter'&gt;\n</code></pre>"},{"location":"ApiReference/Initializer/initializer/#initialize_llm","title":"initialize_llm","text":"<p>This method instanciate the llm agent based on the configuration provided in the initializer.</p> <p>Returns:</p> <ul> <li><code>LlmAgent</code>: The llm agent.</li> </ul>"},{"location":"ApiReference/Initializer/initializer/#usage-example_2","title":"Usage Example","text":""},{"location":"ApiReference/Initializer/initializer/#code_2","title":"Code","text":"<pre><code>llm_agent = initializer.initialize_llm()\n\nprint(type(llm_agent))\n</code></pre>"},{"location":"ApiReference/Initializer/initializer/#output_2","title":"output","text":"<pre><code>&lt;class 'hxm_rag.llm.llm.LlmAgent.LlmAgent'&gt;\n</code></pre>"},{"location":"ApiReference/Models/Models/block/","title":"Block","text":""},{"location":"ApiReference/Models/Models/block/#overview","title":"Overview","text":"<p>The Block is the leaf node of the hexamind data representation. It is the only element that can contain raw content. The Block doesn't have any behavior.  <pre><code>\n%%{init: {'themeVariables': { 'primaryColor': '#ffdddd'}}}%%\ngraph TD\n    classDef red fill:#ffdddd,stroke:#ff0000,stroke-width:2px;\n\n    subgraph Level0\n        container1[\"Root Container\"]\n    end\n\n    subgraph Level1\n        container2[\"Container\"]\n        container3[\"Container\"]\n    end\n\n    subgraph Level2\n        container4[\"Container\"]\n        container5[\"Container\"]\n        container6[\"Container\"]\n        container7[\"Container\"]\n    end\n\n    subgraph Level3\n        block1[\"Block\"]\n        block2[\"Block\"]\n        block3[\"Block\"]\n        block4[\"Block\"]\n        class block1,block2,block3,block4 red\n    end\n\n    container1 --&gt; container2\n    container1 --&gt; container3\n    container2 --&gt; container4\n    container2 --&gt; container5\n    container3 --&gt; container6\n    container3 --&gt; container7\n    container4 --&gt; block1\n    container5 --&gt; block2\n    container6 --&gt; block3\n    container7 --&gt; block4\n</code></pre></p>"},{"location":"ApiReference/Models/Models/block/#rules","title":"Rules","text":"<p>The following rules are applied when creating this structure : </p> <ul> <li>A container can contain other containers or blocks</li> <li>A block can only contain raw content and don't have any children</li> <li>A container can contain multiple children</li> <li>A block is always contained by it own parent container</li> </ul>"},{"location":"ApiReference/Models/Models/block/#properties","title":"Properties","text":"<p>A Block, as well as a Container, inherit from the same abstract class <code>Element</code>.</p> <p>The Block is the object use in the leaf node of the hexamind tree representation of a document. But it is also the object retrieve by the retriver in the vector db. Every sources retrieved is then converted to a block object, and a distance from the query is associated to it.</p>"},{"location":"ApiReference/Models/Models/block/#properties_1","title":"Properties","text":"<p>Constructor Parameters</p> <ul> <li><code>content</code>(str): The content of the block.</li> <li><code>parent_document</code>(Document): The parent document of the block.</li> <li><code>parent_container</code>(Container): The parent container of the block.</li> <li><code>distance</code>(int): In the RAG model, represents the distance between the block and the query. </li> </ul> <p>Attributes</p> <ul> <li><code>content</code>(str): The content of the block.</li> <li><code>parent_document</code>(Document): The parent document of the block.</li> <li><code>parent_container</code>(Container): The parent container of the block.</li> <li><code>distance</code>(int): In the RAG model, represents the distance between the block and the query.</li> <li><code>level</code>(int): The level of the block in the document.</li> </ul>"},{"location":"ApiReference/Models/Models/block/#methods","title":"Methods","text":""},{"location":"ApiReference/Models/Models/block/#get_content","title":"get_content","text":"<p>Return the content of the block.</p>"},{"location":"ApiReference/Models/Models/block/#to_dict","title":"to_dict","text":"<p>Return a dictionary representation of the block.</p>"},{"location":"ApiReference/Models/Models/block/#from_metadata","title":"from_metadata","text":"<p>Create a block object from a metadata dictionary. This method is used to create a block object from the vector db.</p> <p>Parameters</p> <ul> <li><code>text_content</code>(str): The content of the block.</li> <li><code>metadata</code>(dict): The metadata of the block.</li> <li><code>meta_distance</code>(int): The distance of the block from the query.</li> </ul> <p>Returns</p> <ul> <li><code>Block</code>: The block object created from the metadata.</li> </ul>"},{"location":"ApiReference/Models/Models/block/#usage-example","title":"Usage Example","text":""},{"location":"ApiReference/Models/Models/block/#code","title":"Code","text":"<pre><code>blocks = []\nfor content, metadata, distance in zip(contents, metadatas, distances):\n    block = Block.from_metadata(content, metadata, distance)\n    blocks.append(block)\n</code></pre>"},{"location":"ApiReference/Models/Models/container/","title":"Container","text":""},{"location":"ApiReference/Models/Models/container/#overview","title":"Overview","text":"<p>The container is the principal component of the hxm_rag data representation. It is a recursive structure that can contain other containers or block. </p> <p>Below is the hxm_rag representation of a document where container embark all the behavior and block embark only the raw content. </p> <pre><code>\n%%{init: {'themeVariables': { 'primaryColor': '#ffdddd'}}}%%\ngraph TD\n    classDef red fill:#ffdddd,stroke:#ff0000,stroke-width:2px;\n\n    subgraph Level0\n        container1[\"Root Container\"]\n        class container1 red\n    end\n\n    subgraph Level1\n        container2[\"Container\"]\n        container3[\"Container\"]\n        class container2,container3 red\n    end\n\n    subgraph Level2\n        container4[\"Container\"]\n        container5[\"Container\"]\n        container6[\"Container\"]\n        container7[\"Container\"]\n        class container4,container5,container6,container7 red\n    end\n\n    subgraph Level3\n        block1[\"Block\"]\n        block2[\"Block\"]\n        block3[\"Block\"]\n        block4[\"Block\"]\n    end\n\n    container1 --&gt; container2\n    container1 --&gt; container3\n    container2 --&gt; container4\n    container2 --&gt; container5\n    container3 --&gt; container6\n    container3 --&gt; container7\n    container4 --&gt; block1\n    container5 --&gt; block2\n    container6 --&gt; block3\n    container7 --&gt; block4\n</code></pre>"},{"location":"ApiReference/Models/Models/container/#rules","title":"Rules","text":"<p>The following rules are applied when creating this structure : </p> <ul> <li>A container can contain other containers or blocks</li> <li>A block can only contain raw content and don't have any children</li> <li>A container can contain multiple children</li> <li>A block is always contained by it own parent container</li> </ul>"},{"location":"ApiReference/Models/Models/container/#properties","title":"Properties","text":"<p>A container, as well as the block, inherit from the same abstract class <code>Element</code>.</p> <p>The difference is that the container is the only element that bring with it all the behavior that can be applied on text.  For instance a text summary will be store inside the container.</p>"},{"location":"ApiReference/Models/Models/container/#properties_1","title":"Properties","text":"<p>Constructor parameters</p> <ul> <li><code>parent_document</code> : The parent document of the container</li> <li><code>parent_container</code> : The parent container of the container</li> <li><code>level</code> : The level of the container in the document</li> </ul> <p>Attributes</p> <ul> <li><code>uid</code> : The unique identifier of the container. Inherited from Element class</li> <li><code>parent_document</code> : The parent document of the container</li> <li><code>parent_container</code> : The parent container of the container</li> <li><code>parent_document_uid</code> : The uid of the parent document</li> <li><code>parent_container_uid</code> : The uid of the parent container</li> <li><code>children</code> : The children of the container</li> <li><code>level</code> : The level of the container in the document</li> <li><code>content</code> : The content of the container. Concatenation of all the content of the children</li> <li><code>embeddings</code> : The embeddings of the container.</li> <li><code>chunk_id</code> : The chunk id of the container</li> <li><code>chunk</code> : The chunk id of the container</li> <li><code>metadatas</code> : The metadata of the container</li> <li><code>summary</code> : The summary of the container</li> <li><code>summary_embeddings</code> : The embeddings of the summary</li> <li><code>summary_chunk_id</code> : The chunk id of the summary</li> <li><code>summary_chunk</code> : The chunk id of the summary</li> <li><code>summary_metadatas</code> : The metadata of the summary</li> </ul>"},{"location":"ApiReference/Models/Models/container/#methods","title":"Methods","text":""},{"location":"ApiReference/Models/Models/container/#get_content","title":"get_content","text":"<p>Return the content of the container. Meaning the concatenation of all the content of the children.</p>"},{"location":"ApiReference/Models/Models/container/#add_child","title":"add_child","text":"<p>Add a child to the container</p> <p>Parameters</p> <ul> <li><code>child</code> (Element): The child to add to the container</li> </ul>"},{"location":"ApiReference/Models/Models/container/#from_dict","title":"from_dict","text":"<p>classmethod to create a container from a dictionary</p> <p>Parameters</p> <ul> <li><code>structure_dict</code> (dict): The dictionary to create the container from</li> <li><code>parent_document</code> (Document): The parent document of the container. Default to None</li> <li><code>parent_container</code> (Container): The parent container of the container. Default to None</li> </ul>"},{"location":"ApiReference/Models/Models/container/#get_embeddings","title":"get_embeddings","text":"<p>Return the embeddings of the container</p> <p>Parameters</p> <ul> <li><code>llm_agent</code> (LlmAgent): The agent to use to generate the embeddings</li> </ul>"},{"location":"ApiReference/Models/Models/container/#get_summaries","title":"get_summaries","text":"<p>Return the summary of the container. Populating from the container to the children. Each container will have a summary that is the summary of all the children.</p> <p>Parameters</p> <ul> <li><code>llm_agent</code> (LlmAgent): The agent to use to generate the summary</li> </ul>"},{"location":"ApiReference/Models/Models/container/#to_dict","title":"to_dict","text":"<p>Return a dictionary representation of the container</p>"},{"location":"ApiReference/Models/Models/container/#note","title":"Note","text":"<p>This class has not the purpose to be used by the user but this is still the main component of the library. Every other component could use this class when working with documents.</p>"},{"location":"ApiReference/Models/Models/document/","title":"Document","text":"<p>Note: This document is a work in progress. The content and structure may change.</p>"},{"location":"ApiReference/Models/Models/document/#overview","title":"Overview","text":"<p>The document class encapsulates the structure of a real document into the hxm_rag representation.  This is the global entry point for all the data manupulation.</p> <p>Attributes:</p> <ul> <li><code>document_structure</code> (Dict): The structure of the document.</li> </ul>"},{"location":"ApiReference/Models/Models/document/#usage-example","title":"Usage Example","text":"<pre><code>dict_structure = WordReader(\"path/to/word_file\").get_document_structure()\ndocument = Document(dict_structure)\n</code></pre>"},{"location":"ApiReference/Models/Models/document/#methods","title":"Methods","text":""},{"location":"ApiReference/Models/Models/document/#prepare_for_ingestion","title":"prepare_for_ingestion","text":"<p>The method will population every content of a child container to it parent container until reaching the root container. Basically it will create a mutliple level content structure.</p>"},{"location":"ApiReference/Models/Models/document/#usage-example_1","title":"Usage Example","text":"<pre><code>dict_structure = WordReader(\"path/to/word_file\").get_document_structure()\ndocument = Document(dict_structure)\ndocument.prepare_for_ingestion()\n</code></pre>"},{"location":"ApiReference/Models/Models/element/","title":"Element","text":""},{"location":"ApiReference/Models/Models/element/#overview","title":"Overview","text":"<p>The element object reperesents the base element of the structure. The container and the block class are elements and inherit from this class. </p>"},{"location":"ApiReference/Models/Models/element/#element_1","title":"Element","text":""},{"location":"ApiReference/Models/Models/element/#properties","title":"Properties","text":"<p>Attributes</p> <ul> <li><code>uid</code>(str): The uid of the element. </li> <li><code>content</code>(str) : the content of the element</li> </ul>"},{"location":"ApiReference/Models/Models/element/#methods","title":"Methods","text":"<p>These methods must be implemented by the child class.</p>"},{"location":"ApiReference/Models/Models/element/#get_content","title":"get_content","text":""},{"location":"ApiReference/Models/Models/element/#to_dict","title":"to_dict","text":""},{"location":"ApiReference/Models/Readers/html_reader/","title":"HtmlReader","text":""},{"location":"ApiReference/Models/Readers/markdown_reader/","title":"MardownReader","text":""},{"location":"ApiReference/Models/Readers/word_reader/","title":"WordReader","text":""},{"location":"ApiReference/Retriever/retriever/","title":"Retriever","text":""},{"location":"ApiReference/Retriever/retriever/#overview","title":"Overview","text":"<p>The Retriever is the component that will proceed the data retrieval from the database. It will be responsible for the similarity search. </p>"},{"location":"ApiReference/Retriever/retriever/#properties","title":"Properties","text":"<p>Attributes</p> <ul> <li><code>db_client</code>(IDbClient): The database client that will be used to retrieve the data.</li> <li><code>llm_agent</code>(LLMAgent): The agent that will be used. </li> </ul>"},{"location":"ApiReference/Retriever/retriever/#methods","title":"Methods","text":""},{"location":"ApiReference/Retriever/retriever/#similarity_search","title":"similarity_search","text":"<p>Perform a similarity search on the database.</p> <p>Parameters</p> <ul> <li><code>query</code>(str): The query to search for.</li> </ul> <p>Returns</p> <ul> <li><code>List[Block]</code>: The list of blocks retrieved from the database.</li> </ul>"},{"location":"ApiReference/Retriever/retriever/#usage-example","title":"Usage Example","text":""},{"location":"ApiReference/Retriever/retriever/#code","title":"Code","text":"<pre><code>retriever = Retriever(db_client, llm_agent)\n\nblocks = retriever.similarity_search(\"How to create a new document?\")\n</code></pre>"},{"location":"ApiReference/Utils/env/","title":"Env Template","text":""},{"location":"ApiReference/Utils/env/#overview","title":"Overview","text":"<p>The library provided also a utils to automatically generate a .env.template file to configure your project.</p>"},{"location":"ApiReference/Utils/env/#how-to-use-it","title":"How to use it","text":"<pre><code>hxmrag-env --destination /path/to/destination/folder/for/env/ \n</code></pre>"},{"location":"ApiReference/Utils/env/#env-file","title":"Env file","text":"<p>This is what the template env file will look like:</p> <pre><code>#.env.template\n# This file contains the environment variables that are used by the application.\n# You should copy this file to .env and fill in the values for your environment.\n# The hexsrag-env command will copy the .env for you. \n\n# Database\nDATABASE_PATH=path/to/database\nCOLLECTION_NAME=collection_name\nDB_NAME=db_name\n\n#API_DB_NAME = api_db_name\n#API_DB_HOST = api_db_host\n#API_DB_PORT = api_db_port\n#API_DB_USER = api_db_user\n#API_DB_PASSWORD = api_db_password\n#ES_CLOUD_ID = es_cloud_id\n#ES_API_KEY = es_api_key\n#ES_CA_CERT = es_ca_cert\n#ES_SSL_ASSERT = es_ssl_assert\n\n# LLM\nLLM_NAME=llm_name\nLLM_API_KEY=llm_api_key\n#LLM_MODEL=llm_model # e.g. \"gpt-3.5-turbo\" or \"mistral-large-latest\" this name is linked to the LLM_NAME and LLM_API_KEY (not a mandatory variable)\n#LLM_EMBED_MODEL=llm_embed_model # e.g. \"text-embedding-3-large\" or \"mistral-embed\" this name is linked to the LLM_NAME and LLM_API_KEY (not a mandatory variable)\n</code></pre>"},{"location":"ApiReference/Utils/Llm/chat_message/","title":"ChatMessage","text":""},{"location":"ApiReference/Utils/Llm/chat_message/#overview","title":"Overview","text":"<p>Utils with some function used to create the appropriate chat message for the client used. </p>"},{"location":"ApiReference/Utils/Llm/chat_message/#mistralchatmessage","title":"MistralChatMessage","text":"<p>Parameters</p> <ul> <li><code>role</code>(str): The role of the user.</li> <li><code>content</code>(str): The text of the message.</li> </ul> <p>Returns</p> <ul> <li><code>ChatMessage</code>: The final chat message.</li> </ul>"},{"location":"ApiReference/Utils/Llm/template/","title":"Template","text":""},{"location":"ApiReference/Utils/Llm/template/#overview","title":"Overview","text":"<p>This is the class where the prompt template are defined.  There is one prompt template by LlmAgent function. </p>"},{"location":"ApiReference/Utils/Llm/template/#templates","title":"Templates","text":""},{"location":"ApiReference/Utils/Llm/template/#generate_paragraph","title":"generate_paragraph","text":"<p>Generate a paragraph from the prompt.</p> <p>Parameters</p> <ul> <li><code>query</code>(str): The user query.</li> <li><code>context</code>(str): The context related to the user query.</li> <li><code>histo</code> (List[(str,str)]): The history of the conversation.</li> </ul> <p>Returns</p> <ul> <li><code>str</code>: The final prompt.</li> </ul>"},{"location":"ApiReference/Utils/Llm/template/#translate","title":"translate","text":"<p>Translate the prompt to another language.</p> <p>Parameters</p> <ul> <li><code>text</code>(str): The prompt to be translated.</li> </ul> <p>Returns</p> <ul> <li><code>str</code>: The final prompt. Only english is supported for now.</li> </ul>"},{"location":"ApiReference/Utils/Llm/template/#summarize_paragraph","title":"summarize_paragraph","text":"<p>Summarize a paragraph.</p> <p>Parameters</p> <ul> <li><code>prompt</code>(str): The paragraph to be summarized.</li> <li><code>location</code>(str): The location of the paragraph.</li> <li><code>context</code>(str): The context of the paragraph.</li> <li><code>language</code>(str): The language of the paragraph.</li> </ul> <p>Returns</p> <ul> <li><code>str</code>: The final prompt.</li> </ul>"},{"location":"ApiReference/Utils/Llm/template/#detect_language","title":"detect_language","text":"<p>Detect the language of a paragraph.</p> <p>Parameters</p> <ul> <li><code>text</code>(str): The paragraph to detect the language.</li> </ul> <p>Returns</p> <ul> <li><code>str</code>: The final prompt.</li> </ul>"},{"location":"ApiReference/llm/chat_message_factory/","title":"ChatMessageFactory","text":"<p>Note : The <code>ChatMessageFactory</code> is still under development and will be updated soon.</p>"},{"location":"ApiReference/llm/chat_message_factory/#overview","title":"Overview","text":"<p>This factory is only used with the models self-hosted. It is responsible for creating the chat messages to send to the model.</p>"},{"location":"ApiReference/llm/chat_message_factory/#chatmessagefactory_1","title":"ChatMessageFactory","text":"<p>Attributes:</p> <ul> <li><code>model_type</code> (str): The type of the model.</li> </ul>"},{"location":"ApiReference/llm/chat_message_factory/#methods","title":"Methods","text":""},{"location":"ApiReference/llm/chat_message_factory/#create_chat_message","title":"create_chat_message","text":"<p>Create a chat message based on the model type.</p> <p>Parameters:</p> <ul> <li><code>role</code> (str): The role of the message. ('user' or 'agent')</li> <li><code>content</code> (str): The content of the message.</li> </ul>"},{"location":"ApiReference/llm/illm_client/","title":"ILlmClient","text":""},{"location":"ApiReference/llm/illm_client/#overview","title":"Overview","text":"<p>The <code>ILlmClient</code> interface is used to define the methods that the llm client should implement. All the adapters inherit from this interface. You can create your own adapter thanks to this interface.</p>"},{"location":"ApiReference/llm/illm_client/#illmclient_1","title":"ILlmClient","text":""},{"location":"ApiReference/llm/illm_client/#methods","title":"Methods","text":""},{"location":"ApiReference/llm/illm_client/#chat","title":"chat","text":"<p>Chat with the llm model.</p> <p>Parameters:</p> <ul> <li><code>messages</code> (str): The messages to send to the llm model.</li> <li><code>temperature</code> (float): The temperature of the model. </li> </ul>"},{"location":"ApiReference/llm/illm_client/#create_chat_message","title":"create_chat_message","text":"<p>Create a chat message.</p> <p>Parameters:</p> <ul> <li><code>role</code> (str): The role of the message. ('user' or 'agent')</li> <li><code>content</code> (str): The content of the message.</li> </ul>"},{"location":"ApiReference/llm/illm_client/#embeddings","title":"embeddings","text":"<p>Get the embeddings of the text.</p> <p>Parameters:</p> <ul> <li><code>input</code> (str): The text to get the embeddings from.</li> </ul>"},{"location":"ApiReference/llm/llm_agent/","title":"LlmAgent","text":""},{"location":"ApiReference/llm/llm_agent/#overview","title":"Overview","text":"<p>The <code>LlmAgent</code> implement all the logic behind the RAG model. This is the class reponsible for communication with the model and return the results to the user.</p> <p>Attributes:</p> <ul> <li><code>client</code> (ILlmClient): The client to communicate with the model.</li> </ul>"},{"location":"ApiReference/llm/llm_agent/#methods","title":"Methods","text":""},{"location":"ApiReference/llm/llm_agent/#generate_paragraph","title":"generate_paragraph","text":"<p>This is a method used to generate a reponse based on a user query. </p> <p>Parameters:</p> <ul> <li><code>query</code> (str): The query to generate the response.</li> <li><code>context</code> (dict): The context of the query.</li> <li><code>histo</code> (List[(str, str)]): The history of the conversation.</li> <li><code>language</code> (str): The language of the query.</li> </ul> <p>Returns:</p> <ul> <li><code>str</code>: The response generated by the model.</li> </ul>"},{"location":"ApiReference/llm/llm_agent/#usage-example","title":"Usage example","text":""},{"location":"ApiReference/llm/llm_agent/#code","title":"Code","text":"<pre><code>llm_adapter = LlmAdapterFactory.create_adapter(llm_name='mistral', on_premise=False, api_key='api_key', model='mistral-large', embed_model='mistral-embed')\n\nllm_agent = LlmAgent(client=llm_adapter)\n\nresponse = llm_agent.generate_paragraph(query='What is the capital of France?', context={}, histo=[], language='en')\n</code></pre>"},{"location":"ApiReference/llm/llm_agent/#translate","title":"translate","text":"<p>This is a method used to translate a text from a language to another.</p> <p>Parameters:</p> <ul> <li><code>text</code> (str): The text to translate.</li> </ul> <p>Returns:</p> <ul> <li><code>str</code>: The translated text.</li> </ul>"},{"location":"ApiReference/llm/llm_agent/#summarize_paragraph","title":"summarize_paragraph","text":"<p>This is a method used to summarize a paragraph.</p> <p>Parameters:</p> <ul> <li><code>prompt</code> (str): The paragraph to summarize.</li> <li><code>title_doc</code> (str): The title of the document.</li> <li><code>title_para</code> (str): The title of the paragraph.</li> </ul> <p>Returns:</p> <ul> <li><code>str</code>: The summarized paragraph.</li> </ul>"},{"location":"ApiReference/llm/llm_agent/#usage-example_1","title":"Usage example","text":""},{"location":"ApiReference/llm/llm_agent/#code_1","title":"Code","text":"<pre><code>llm_agent = LlmAgent(client=llm_adapter)\n\nsummary = llm_agent.summarize_paragraph(prompt='This is a paragraph to summarize.', title_doc='Document', title_para='Paragraph')\n</code></pre>"},{"location":"ApiReference/llm/llm_agent/#detect_language","title":"detect_language","text":"<p>This is a method used to detect the language of a text.</p> <p>Parameters:</p> <ul> <li><code>text</code> (str): The text to detect the language.</li> </ul> <p>Returns:</p> <ul> <li><code>str</code>: The detected language.</li> </ul>"},{"location":"ApiReference/llm/llm_agent/#get_embeddings","title":"get_embeddings","text":"<p>This is a method used to get the embeddings of a text.</p> <p>Parameters:</p> <ul> <li><code>text</code> (str): The text to get the embeddings.</li> </ul> <p>Returns:</p> <ul> <li><code>List[float]</code>: The embeddings of the text.</li> </ul>"},{"location":"ApiReference/llm/llm_agent/#usage-example_2","title":"Usage example","text":""},{"location":"ApiReference/llm/llm_agent/#code_2","title":"Code","text":"<pre><code>llm_agent = LlmAgent(client=llm_adapter)\n\nembeddings = llm_agent.get_embeddings(text='This is a text to get the embeddings.')\n</code></pre>"},{"location":"ApiReference/llm/llm_factory/","title":"LlmAdapterFactory","text":""},{"location":"ApiReference/llm/llm_factory/#overview","title":"Overview","text":"<p>This llm factory is responsible for perfectly instanciate the llm agent based on the configuration provided. </p>"},{"location":"ApiReference/llm/llm_factory/#llmadapterfactory_1","title":"LlmAdapterFactory","text":""},{"location":"ApiReference/llm/llm_factory/#methods","title":"Methods","text":""},{"location":"ApiReference/llm/llm_factory/#create_adapter","title":"create_adapter","text":"<p>Create a llm agent based on the llm type. Note that this method can create the proper agent either from a self-hosted model or from the APIs (like Mistral or OpenAI). You only have to specify if the model is on premise or not.</p> <p>Parameters:</p> <ul> <li><code>llm_name</code> (str): The name of the llm model you want to use. Mandatory if the model is not on premise.</li> <li><code>on_premise</code> (bool): If the model is on premise or not. Default is False.</li> <li><code>kwargs</code> (dict): The keyword arguments to pass to the llm agent.<ul> <li>For API models:<ul> <li><code>api_key</code> (str): The api key of the Mistral model.</li> <li><code>model</code> (str): The model to use for the llm agent.</li> <li><code>embed_model</code> (str): The model to use for the embeddings.</li> </ul> </li> <li>For on premise models:<ul> <li><code>inference_endpoint</code> (str): The endpoint of the model.</li> <li><code>embeddings_endpoint</code> (str): The endpoint of the embeddings.</li> </ul> </li> </ul> </li> </ul> <p>Returns:</p> <ul> <li><code>ILlmClient</code>: Returns on instance of the llm client adapter interface. </li> </ul>"},{"location":"ApiReference/llm/llm_factory/#api-models-supported","title":"API models supported","text":"<p>At the moment the following API models are supported:</p> <ul> <li>Mistral</li> <li>OpenAI</li> </ul>"},{"location":"ApiReference/llm/llm_factory/#usage-example","title":"Usage Example","text":""},{"location":"ApiReference/llm/llm_factory/#code","title":"Code","text":"<pre><code>llm_adapter = LlmAdapterFactory.create_adapter(llm_name='mistral', on_premise=False, api_key='api_key', model='mistral-large', embed_model='mistral-embed')\n\nllm_agent = LlmAgent(client=llm_adapter)\n</code></pre>"},{"location":"ApiReference/llm/mistral_client/","title":"MistralClientAdapter","text":""},{"location":"ApiReference/llm/mistral_client/#overview","title":"Overview","text":"<p>The <code>MistralClientAdapter</code> class is used to interface with the Mistral API. This class implements the <code>ILlmClient</code> interface.</p> <p>Attributes:</p> <ul> <li><code>client</code> (MistralClient): The Mistral client used to interface with the Mistral API.</li> <li><code>model</code> (str): The model to use for the llm agent.</li> <li><code>embed_model</code> (str): The model to use for the embeddings.</li> </ul>"},{"location":"ApiReference/llm/mistral_client/#methods","title":"Methods","text":""},{"location":"ApiReference/llm/mistral_client/#chat","title":"chat","text":"<p>Chat with the Mistral model.</p> <p>Parameters:</p> <ul> <li><code>messages</code> (str): The messages to send to the Mistral model.</li> <li><code>temperature</code> (float): The temperature of the model.</li> </ul>"},{"location":"ApiReference/llm/mistral_client/#create_chat_message","title":"create_chat_message","text":"<p>Create a chat message.</p> <p>Parameters:</p> <ul> <li><code>role</code> (str): The role of the message. ('user' or 'agent')</li> <li><code>content</code> (str): The content of the message.</li> </ul>"},{"location":"ApiReference/llm/mistral_client/#embeddings","title":"embeddings","text":"<p>Get the embeddings of the text.</p> <p>Parameters:</p> <ul> <li><code>input</code> (str): The text to get the embeddings from.</li> </ul>"},{"location":"ApiReference/llm/on_premise_client/","title":"LlmOpAdapter","text":"<p>Note: The <code>LlmOpAdapter</code> is still under development and will be updated soon.</p>"},{"location":"ApiReference/llm/on_premise_client/#overview","title":"Overview","text":"<p>The <code>LlmOpAdapter</code> class is used to interface with your self-hosted model. This class implements the <code>ILlmClient</code> interface. </p> <p>Attributes:</p> <ul> <li><code>inference_endpoint</code> (str): The endpoint of the model.</li> <li><code>embeddings_endpoint</code> (str): The endpoint of the embeddings.</li> <li><code>chat_method</code> : You must pass the chat message method you want to use according to the model. For now only the Mistral chat method is implemented.</li> </ul>"},{"location":"ApiReference/llm/on_premise_client/#methods","title":"Methods","text":""},{"location":"ApiReference/llm/on_premise_client/#chat","title":"chat","text":"<p>Chat with the llm model.</p> <p>Parameters:</p> <ul> <li><code>messages</code> (str): The messages to send to the llm model.</li> <li><code>temperature</code> (float): The temperature of the model.</li> </ul>"},{"location":"ApiReference/llm/on_premise_client/#create_chat_message","title":"create_chat_message","text":"<p>Create a chat message.</p> <p>Parameters:</p> <ul> <li><code>role</code> (str): The role of the message. ('user' or 'agent')</li> <li><code>content</code> (str): The content of the message.</li> </ul>"},{"location":"ApiReference/llm/on_premise_client/#embeddings","title":"embeddings","text":"<p>Get the embeddings of the text.</p> <p>Parameters:</p> <ul> <li><code>input</code> (str): The text to get the embeddings from.</li> </ul>"},{"location":"ApiReference/llm/openai_client/","title":"OpenAiClientAdapter","text":""},{"location":"ApiReference/llm/openai_client/#overview","title":"Overview","text":"<p>The <code>OpenAiClientAdapter</code> class is used to interface with the OpenAi API. This class implements the <code>ILlmClient</code> interface.</p> <p>Attributes:</p> <ul> <li><code>client</code> (OpenAiClient): The OpenAi client used to interface with the OpenAi API.</li> <li><code>model</code> (str): The model to use for the llm agent.</li> <li><code>embed_model</code> (str): The model to use for the embeddings.</li> </ul>"},{"location":"ApiReference/llm/openai_client/#methods","title":"Methods","text":""},{"location":"ApiReference/llm/openai_client/#chat","title":"chat","text":"<p>Chat with the OpenAi model.</p> <p>Parameters:</p> <ul> <li><code>messages</code> (str): The messages to send to the OpenAi model.</li> <li><code>temperature</code> (float): The temperature of the model.</li> </ul>"},{"location":"ApiReference/llm/openai_client/#create_chat_message","title":"create_chat_message","text":"<p>Create a chat message.</p> <p>Parameters:</p> <ul> <li><code>role</code> (str): The role of the message. ('user' or 'agent')</li> <li><code>content</code> (str): The content of the message.</li> </ul>"},{"location":"ApiReference/llm/openai_client/#embeddings","title":"embeddings","text":"<p>Get the embeddings of the text.</p> <p>Parameters:</p> <ul> <li><code>input</code> (str): The text to get the embeddings from.</li> </ul>"},{"location":"UserGuide/getting_started/","title":"Getting Started","text":"<p>This is a guide to help you get started with the hexamind library. </p>"},{"location":"UserGuide/getting_started/#installation","title":"Installation","text":""},{"location":"UserGuide/getting_started/#using-pip","title":"Using pip","text":"<p>You should be able to install the library using pip. But you must have the hxm_rag repository cloned on your local machine. Because this library is private and not yet deploy on private registry. </p> <pre><code>git clone https://github.com/HexamindOrganisation/hexamind.git\n</code></pre> <p>Then you can install the library using pip.</p> <pre><code>pip install -e path/to/hexamind\n</code></pre>"},{"location":"UserGuide/getting_started/#usage","title":"Usage","text":"<p>The library serves many purpose and can be used not only for RAG solutions but also when you need to parse some document and just use a Llm agent. </p>"},{"location":"UserGuide/getting_started/#parsing-a-docx-file","title":"Parsing a docx file","text":"<p>Here is a simple example of how to parse a docx file using the WordReader class. </p> <pre><code>from hxm_rag.model import WordReader\n\n# Create an instance of the WordReader class\n\nword_reader = WordReader(\"path/to/your/docx/file\")\n\n# Create a nested dictionnary structure of the document\n\ndoc_structure = word_reader.get_document_structure()\n</code></pre> <p>this sample should give you a nested dictionnary structure that must look like this:</p> <pre><code>  {\n        'type' : 'container' or 'block',\n        'children' : [list of nested dictionaries],\n        'content' : None or string,\n        'level' : int,\n        'parent' : parent dictionary\n    }\n</code></pre> <p>See readers for more information about the readers available in the library and the return format.</p>"},{"location":"UserGuide/getting_started/#converting-a-nested-dictionnary-into-a-document-object","title":"Converting a nested dictionnary into a Document object","text":"<p>To get more information about the document click here </p> <p>You can then convert the nested dictionnary into the hxm_rag Document object. </p> <pre><code>from hxm_rag.model import Document\n\ndoc = Document(doc_structure)\n</code></pre>"},{"location":"UserGuide/getting_started/#using-the-llm-agent","title":"Using the LLm agent","text":"<p>You can use select the proper agent in many ways, feel free to explore the llm module to see the different model supported by the library. </p> <pre><code>from llm import MistralClientAdapter, LlmAgent\nfrom mistralai import MistralClient\n\n# Create an instance of the MistralClient class\n\nmistral_client = MistralClientAdapter(MistralClient('your_mistral_api_key'))\n\n# Create an instance of the LlmAgent class\n\nllm_agent = LlmAgent(mistral_client)\n</code></pre> <p>A factory method is also available to instanciate the client automatically. This can be coupled with the Initializer class that can initialize every component needed in your solution. </p>"},{"location":"UserGuide/installation/","title":"Installation","text":"<p>The library can be installed like any other regular library. The only constraint here is to have the hexamind repository cloned on your local machine. In a future release, we will deploy the library on a private registry. </p>"},{"location":"UserGuide/installation/#clone-the-private-github-repository","title":"Clone the private github repository","text":"<pre><code>git clone https://github.com/HexamindOrganisation/hexamind.git\n</code></pre> <p>You must have access to the repository to clone it. If you don't, please contact the repository owner.</p>"},{"location":"UserGuide/installation/#install-the-library-using-pip","title":"Install the library using pip","text":"<pre><code>pip install -e path/to/hexamind\n</code></pre>"}]}